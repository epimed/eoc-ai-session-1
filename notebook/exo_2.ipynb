{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2 : Régression Logistique (LR) et Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reprise du code déjà réalisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(classifier, X_train, X_test, y_train, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred_train = classifier.predict(X_train)\n",
    "    y_pred_test = classifier.predict(X_test)\n",
    "    accuracy_train = metrics.accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = metrics.accuracy_score(y_test, y_pred_test)\n",
    "    print('Train accuracy:', '{:.3f}'.format(accuracy_train), 'Test accuracy:', '{:.3f}'.format(accuracy_test))\n",
    "    return accuracy_train, accuracy_test, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "data = pd.read_csv('../data/colon_cancer.csv', sep=';', index_col='id_sample')\n",
    "y = data['tissue_status']\n",
    "X = data.select_dtypes('number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/4, random_state=random_state, stratify=y)\n",
    "print('Train:', X_train.shape, 'Test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1. Appliquer une normalisation centrée-réduite aux données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour faciliter la convergence des algorithmes de machine learning, il est fortément conseillé de normaliser les données. Une approche standard est la normalisation centrée-réduite qui soustrait la moyenne et divise par l'écart-type les valeurs d'expression.\n",
    "\n",
    "**Attention !** Le calcul de la moyenne $\\mu$ et l'écart-type $\\sigma$ doit être réalisé **uniquement sur le dataset d'entrainement**. Le dataset de test ne doit pas être utilisé dans le calcul. Il sera normalisé en utilisant les valeurs $\\mu$ et $\\sigma$ calculées sur le dataset d'entrainement.\n",
    "\n",
    "La librairie **scikit-learn** contient un certain nombre de *scalers* qui permettent de réaliser facilement cette normalisation. Ainsi, le scaler `StandardScaler` permet de centrer-réduire les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() # crée un scaler\n",
    "scaler.fit(X_train) # calcule mu et sigma sur X_train uniquement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Décommenter et exécuter les lignes ci-dessous pour afficher mu et sigma pour chaque gène\n",
    "# print('Mean mu', scaler.mean_)\n",
    "# print('Std sigma', scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer les valeurs $\\mu$ et $\\sigma$ calculées pour X_train aux deux datasets : **X_train** et **X_test**. Pour cela, il faut utiliser la méthode `transform` du *scaler*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A exécuter\n",
    "X_train_scaled = scaler.transform(X_train) # numpy object\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, index=X_train.index, columns=X_train.columns) # conversion en pandas DataFrame\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test) # numpy object\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, index=X_test.index, columns=X_test.columns) # conversion en pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après normalisation, la moyenne des valeurs d'expression pour chaque gène dans le dataset **X_train_scaled** doit être égale 0. Vérifiez que c'est réellement le cas. Pour cela, calculez la moyenne à l'aide de la méthode `mean()` et affichez quelques premières valeurs avec `head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled... # à compléter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après normalisation, l'écart-type doit être égal à 1. Vérifiez-le en calculant l'écart-type du dataset **X_train_scaled** à l'aide de la méthode `std()`. Affichez quelques premières valeurs avec `head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled... # à compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. Créer un modèle de régression logistique (LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **régresssion logistique** utilise une fonction analytique, appelée fonction **logistique** ou fonction **sigmoïde**, qui a une forme caractéristique en **S**. En optimisant les coefficients de cette courbe (*max* de vraisemblance ou *min* de cross-entropie), elle permet d'estimer la probabilité pour un échantillon d'appartenir à telle ou telle classe. Par exemple, *tumoral* versus *normal*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logistic_regression.png\" alt=\"Logistic regression\" width=\"600\" aling=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créez le modèle de LR en utilisant les données normalisées et calculer la métrique *accuracy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state=random_state, penalty='none')\n",
    "\n",
    "# accuracy_train, accuracy_test, trained_classifier = calculate_accuracy(classifier, ... , ... , y_train, y_test) # à compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez la matrice de confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.plot_confusion_matrix(trained_classifier, ... , ...) # à compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Est-ce que ce modèle est plus performant que Decision Tree ou Random Forest de l'exercice 1 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. Evaluer l'impact de chaque gène dans le modèle LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après la phase d'entrainement, il est possible de connaître les paramètres $\\beta$ du modèle obtenu. Il sont disponibles dans l'attribut `coef_`. Plus le coefficient $\\beta$ est grand (en valeur absolue), plus l'impact du gène correspondant est important dans le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez les coefficients $\\beta$ pour quelques premiers gènes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame(trained_classifier.coef_[0], index=X_train_scaled.columns, columns=['beta'])\n",
    "coefficients.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Présentez les coefficients $\\beta$ sous forme d'un *barplot*, du plus petit au plus grand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = coefficients.sort_values(by='beta')\n",
    "coefficients.plot.bar(figsize=(15, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quels gènes impactent fortement le modèle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. Analyser la corrélation entre les meilleurs prédicteurs proposés par le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifiez N meilleurs gènes qui impactent le plus fortement le modèle LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "coefficients['abs_beta'] = coefficients['beta'].abs() # calcul des valeurs absolues des beta\n",
    "coefficients = coefficients.sort_values(by='abs_beta', ascending=False) # tri par valeurs absolues\n",
    "top_features = list(coefficients.head(n_features).index) # liste de n meilleurs features\n",
    "print('Top features LR:', top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez un paiplot pour ces gènes, pour estimer qualitativement leur corrélation. Utilisez la librairie *seaborn* de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.pairplot(data[[*top_features, 'tissue_status']], hue='tissue_status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Est-ce que les gènes sont corrélés ? Est-ce qu'il y a un intérêt de les utiliser ensemble pour l'apprentissage du modèle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5. Calculer les performances du modèle LR en utilisant 1, 2, ... n top features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qu'est-ce que fait le code ci-dessous ? Exécutez-le et expliquez le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(top_features)):\n",
    "    selected_features = top_features[0:i+1]\n",
    "    print(selected_features)\n",
    "    accuracy_train, accuracy_test, trained_classifier = calculate_accuracy(classifier, X_train_scaled[selected_features], X_test_scaled[selected_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6. Créer un modèle linéaire de Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le **modèle SVM** cherche à définir une frontière entre deux ou plusieurs classes d'échantillons, en maximisant la marge entre cette frontière et les échantillons les plus proches (vecteurs de support)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"svm.png\" alt=\"Support Vector Machine\" width=\"600\" aling=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créez le modèle SVM en utilisant les données normalisées, calculez la métrique *accuracy* et la matrice de confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "classifier = LinearSVC(random_state=random_state)\n",
    "\n",
    "# accuracy_train, accuracy_test, trained_classifier = calculate_accuracy(...) # à compléter\n",
    "# metrics.plot_confusion_matrix(...) # à compléter\n",
    "accuracy_train, accuracy_test, trained_classifier = calculate_accuracy(classifier, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "metrics.plot_confusion_matrix(trained_classifier, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7. Evaluer l'impact de chaque gène dans le modèle SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame(trained_classifier.coef_[0], index=X_train_scaled.columns, columns=['beta'])\n",
    "\n",
    "coefficients = coefficients.sort_values(by='beta')\n",
    "coefficients.plot.bar(figsize=(15, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients['abs_beta'] = coefficients['beta'].abs()\n",
    "coefficients = coefficients.sort_values(by='abs_beta', ascending=False)\n",
    "top_features = list(coefficients.head(n_features).index)\n",
    "print('Top features SVM:', top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparez le résultat avec LR. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8. Etude de cas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'hôpital *AI-Hospital* a mis au point un nouvel outil diagnostique basé sur les niveaux d'expression d'un panel de 3 gènes. Cet outil a donné les mesures suivantes pour un nouveau patient à l'hôpital :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_patient = {'RNF43': 4.68, 'SLC7A5': 4.10, 'DAO': 7.59} # dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question principale : Est-ce que ce patient est atteint d'un cancer du colon ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Composez un dataset de test **X_test** qui contient un seul échantillon - le nouveau patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame([new_patient], index=['new_patient'])\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = X_test.columns # liste de gènes dans le panel\n",
    "print(panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez la totalité de données disponibles en tant que dataset d'entrainement **X_train**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[panel]\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainez une Régression Logistique. Faites une prédiction pour le patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code à écrire soi-même"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question bonus : Quelle est la probabilité prédite pour ce patient d'avoir un cancer du colon ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indice : Utilisez la méthode `predict_proba()` du modèle à la place de `predict()` pour obtenir la probabilité de prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code à écrire soi-même"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
